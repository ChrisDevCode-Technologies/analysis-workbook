{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activities by Employers/Companies\n",
    "\n",
    "This section generates dummy activity data associated with previously generated company and people data.\n",
    "\n",
    "- Links `Company Name` from `company_data.json`.\n",
    "- Selects RSVP'd and Attended participants from `dummy_data.json` (based on `Youth_ID`).\n",
    "- Produces `activities_data.json` and `activities_data.csv`, appending if they already exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & Constants for Activities\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "activity_types = [\n",
    "    \"Social Responsibility\", \n",
    "    \"Networking\", \n",
    "    \"Recruitment\", \n",
    "    \"Product Launch\", \n",
    "    \"Community Outreach\", \n",
    "    \"Employee Engagement\", \n",
    "    \"Workshop\", \n",
    "    \"Training Session\"\n",
    "]\n",
    "\n",
    "target_audiences = [\"Employees\", \"Public\", \"Partners\", \"Students\", \"Volunteers\", \"Customers\", \"Youth\"]\n",
    "recurrence_options = [\"Daily\", \"Weekly\", \"Monthly\", \"Annually\", \"Ad Hoc\"]\n",
    "feedback_mechanisms = [\"Survey\", \"Feedback Form\", \"None\"]\n",
    "\n",
    "# Helper functions\n",
    "def pick(lst):\n",
    "    return random.choice(lst)\n",
    "\n",
    "def random_boolean():\n",
    "    return random.choice([True, False])\n",
    "\n",
    "def flatten_and_remove_prefix(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_and_remove_prefix(v, new_key, sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            # For CSV, if list of strings/IDs, just join by comma\n",
    "            # If complex structures, could be json.dumps\n",
    "            if v and isinstance(v[0], dict):\n",
    "                val_str = json.dumps(v, ensure_ascii=False)\n",
    "            else:\n",
    "                val_str = \", \".join(map(str, v))\n",
    "            parts = new_key.split(sep, 1)\n",
    "            if len(parts) > 1:\n",
    "                new_key = parts[1]\n",
    "            items.append((new_key, val_str))\n",
    "        else:\n",
    "            val_str = str(v) if v is not None else \"\"\n",
    "            parts = new_key.split(sep, 1)\n",
    "            if len(parts) > 1:\n",
    "                new_key = parts[1]\n",
    "            items.append((new_key, val_str))\n",
    "    return dict(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 250 companies.\n",
      "Total people after sampling: 500\n",
      "Number of Youth IDs available: 500\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load existing company and people data\n",
    "\n",
    "# Set the number of youth to load (custom)\n",
    "# For example, set this to 100 to load exactly 100 youth if available\n",
    "num_youth_to_load = 555  # Adjust this number as needed\n",
    "\n",
    "# Load companies\n",
    "company_filename = '../data/companies.json'\n",
    "companies = []\n",
    "if os.path.exists(company_filename):\n",
    "    with open(company_filename, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            companies = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            companies = []\n",
    "\n",
    "# Load people\n",
    "people_filename = '../data/people.json'\n",
    "people = []\n",
    "if os.path.exists(people_filename):\n",
    "    with open(people_filename, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            people = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            people = []\n",
    "\n",
    "# Sample a custom number of people\n",
    "if people:\n",
    "    if num_youth_to_load > len(people):\n",
    "        # If requested number exceeds available, load all\n",
    "        num_youth_to_load = len(people)\n",
    "    people = random.sample(people, k=num_youth_to_load)\n",
    "\n",
    "# Extract company names\n",
    "company_names = []\n",
    "for c in companies:\n",
    "    basic_info = c.get(\"Basic Information\", {})\n",
    "    cname = basic_info.get(\"company_name\")\n",
    "    if cname:\n",
    "        company_names.append(cname)\n",
    "\n",
    "# Extract Youth IDs from selected people\n",
    "youth_ids = []\n",
    "for p in people:\n",
    "    yid = p.get(\"Youth_ID\")\n",
    "    if yid:\n",
    "        youth_ids.append(yid)\n",
    "\n",
    "print(f\"Loaded {len(companies)} companies.\")\n",
    "print(f\"Total people after sampling: {len(people)}\")\n",
    "print(f\"Number of Youth IDs available: {len(youth_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define activity generation function\n",
    "\n",
    "def generate_activity_data(num_records=5):\n",
    "    # If no companies or youth_ids loaded, handle gracefully\n",
    "    if not company_names:\n",
    "        print(\"No companies available. Please ensure company_data.json has entries.\")\n",
    "        return []\n",
    "    if not youth_ids:\n",
    "        print(\"No people (Youth IDs) available. Please ensure dummy_data.json has entries.\")\n",
    "        return []\n",
    "    \n",
    "    activities = []\n",
    "    for _ in range(num_records):\n",
    "        \n",
    "        # Generate a unique activity_id\n",
    "        # For example, combine timestamp + random characters\n",
    "        unique_part = \"\".join(random.choices(string.ascii_uppercase + string.digits, k=6))\n",
    "        activity_id = f\"ACT-{int(datetime.now(timezone.utc).timestamp())}-{unique_part}\"\n",
    "        \n",
    "        company_name = pick(company_names)\n",
    "        activity_name = fake.catch_phrase()  # just a random phrase as activity name\n",
    "        activity_type = pick(activity_types)\n",
    "        description = fake.sentence(nb_words=15)\n",
    "        target_audience = pick(target_audiences)\n",
    "        \n",
    "        # Random start and end date\n",
    "        start_date = datetime.now() + timedelta(days=random.randint(1,30))\n",
    "        end_date = start_date + timedelta(days=random.randint(1,5))\n",
    "        \n",
    "        # Location (could be physical or virtual)\n",
    "        # 50% chance virtual\n",
    "        if random_boolean():\n",
    "            location = \"Virtual (Online)\"\n",
    "        else:\n",
    "            # use random city/street from faker as location\n",
    "            location = fake.address().replace(\"\\n\", \", \")\n",
    "        \n",
    "        participants_expected = random.randint(10, 500)\n",
    "        \n",
    "        key_partners = []\n",
    "        if random_boolean():\n",
    "            key_partners = [fake.company() for _ in range(random.randint(1,3))]\n",
    "        \n",
    "        activity_goals = fake.sentence(nb_words=10)\n",
    "        \n",
    "        # RSVP'd: pick random subset of youth_ids\n",
    "        rsvp_count = random.randint(1, min(20, len(youth_ids)))\n",
    "        rsvpd_list = random.sample(youth_ids, k=rsvp_count)\n",
    "        \n",
    "        # Attended: subset of RSVP'd\n",
    "        attended_count = random.randint(0, rsvp_count)\n",
    "        attended_list = random.sample(rsvpd_list, k=attended_count)\n",
    "        \n",
    "        # Logistics\n",
    "        is_recurring = random_boolean()\n",
    "        frequency = pick(recurrence_options) if is_recurring else None\n",
    "        budget = None\n",
    "        if random_boolean():\n",
    "            budget = f\"${random.randint(1000,100000)}\"\n",
    "        resources = []\n",
    "        if random_boolean():\n",
    "            resources = [\"Training materials\", \"Equipment\", \"Refreshments\"]\n",
    "        \n",
    "        # Impact Measurement\n",
    "        success_metrics = \"Number of participants, Engagement levels\"\n",
    "        feedback_mechanism = pick(feedback_mechanisms)\n",
    "        if feedback_mechanism == \"None\":\n",
    "            feedback_mechanism = None\n",
    "        \n",
    "        activity_record = {\n",
    "            \"activity_id\": activity_id,\n",
    "            \"Activity Details\": {\n",
    "                \"company_name\": company_name,\n",
    "                \"activity_name\": activity_name,\n",
    "                \"activity_type\": activity_type,\n",
    "                \"description\": description,\n",
    "                \"target_audience\": target_audience,\n",
    "                \"start_date\": start_date.isoformat(),\n",
    "                \"end_date\": end_date.isoformat(),\n",
    "                \"location\": location,\n",
    "                \"number_of_participants_expected\": participants_expected,\n",
    "                \"key_partners_sponsors\": key_partners,\n",
    "                \"activity_goals_outcomes\": activity_goals,\n",
    "                \"rsvpd_list\": rsvpd_list,\n",
    "                \"attended_people\": attended_list\n",
    "            },\n",
    "            \"Logistics\": {\n",
    "                \"is_recurring\": is_recurring,\n",
    "                \"frequency_of_recurrence\": frequency,\n",
    "                \"budget\": budget,\n",
    "                \"resources_needed_provided\": resources\n",
    "            },\n",
    "            \"Impact Measurement\": {\n",
    "                \"success_metrics\": success_metrics,\n",
    "                \"feedback_mechanism\": feedback_mechanism\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        activities.append(activity_record)\n",
    "    return activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 activity records appended to ../data/activities_data.json and ../data/activities_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Generate and append activities to files\n",
    "num_records = 77\n",
    "new_activities = generate_activity_data(num_records)\n",
    "\n",
    "if new_activities:\n",
    "    # Append to JSON\n",
    "    activities_json = '../data/activities_data.json'\n",
    "    existing_activities = []\n",
    "    if os.path.exists(activities_json):\n",
    "        with open(activities_json, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                existing_activities = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_activities = []\n",
    "    existing_activities.extend(new_activities)\n",
    "\n",
    "    with open(activities_json, 'w', encoding='utf-8') as jf:\n",
    "        json.dump(existing_activities, jf, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    # Flatten and write CSV\n",
    "    final_records = [flatten_and_remove_prefix(a) for a in new_activities]\n",
    "    activities_csv = '../data/activities_data.csv'\n",
    "    file_exists = os.path.exists(activities_csv)\n",
    "    \n",
    "    fieldnames_set = set()\n",
    "    for fr in final_records:\n",
    "        fieldnames_set.update(fr.keys())\n",
    "    fieldnames = sorted(fieldnames_set)\n",
    "    \n",
    "    mode = 'a' if file_exists else 'w'\n",
    "    with open(activities_csv, mode=mode, newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for fr in final_records:\n",
    "            writer.writerow(fr)\n",
    "    \n",
    "    print(f\"{num_records} activity records appended to {activities_json} and {activities_csv}.\")\n",
    "else:\n",
    "    print(\"No activities generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Results:\n",
      "Total RSVPd: 799\n",
      "Total Attended: 395\n",
      "Gender breakdown for RSVPd: {'Male': 248, 'Female': 315, 'Not specified': 236}\n",
      "Gender breakdown for Attended: {'Male': 124, 'Female': 146, 'Not specified': 125}\n",
      "Attended Age Groups: {'Under 18': 0, '18-25': 46, '26-40': 103, 'Over 40': 246}\n",
      "Major Age Group of Attendees: Over 40\n",
      "people.csv not found, no CSV update performed.\n"
     ]
    }
   ],
   "source": [
    "# Cell: Analysis and Updating People Data\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Define a function to categorize age\n",
    "def age_group(age):\n",
    "    if age < 18:\n",
    "        return \"Under 18\"\n",
    "    elif 18 <= age <= 25:\n",
    "        return \"18-25\"\n",
    "    elif 26 <= age <= 40:\n",
    "        return \"26-40\"\n",
    "    else:\n",
    "        return \"Over 40\"\n",
    "\n",
    "# Load people data\n",
    "people_filename = '../data/people.json'\n",
    "with open(people_filename, 'r', encoding='utf-8') as f:\n",
    "    people_data = json.load(f)\n",
    "\n",
    "# Create a dict keyed by Youth_ID for easy lookup\n",
    "people_by_id = {}\n",
    "for person in people_data:\n",
    "    yid = person.get(\"Youth_ID\")\n",
    "    if yid:\n",
    "        people_by_id[yid] = person\n",
    "        # Initialize lists for activities (if not present)\n",
    "        person[\"activities_rsvpd\"] = []\n",
    "        person[\"activities_attended\"] = []\n",
    "\n",
    "# Load activities\n",
    "activities_filename = '../data/activities_data.json'\n",
    "with open(activities_filename, 'r', encoding='utf-8') as f:\n",
    "    activities_data = json.load(f)\n",
    "\n",
    "# Counters for analysis\n",
    "total_rsvpd = 0\n",
    "total_attended = 0\n",
    "\n",
    "gender_count_rsvpd = {\"Male\":0, \"Female\":0, \"Not specified\":0}\n",
    "gender_count_attended = {\"Male\":0, \"Female\":0, \"Not specified\":0}\n",
    "\n",
    "age_groups_count_attended = {\"Under 18\":0, \"18-25\":0, \"26-40\":0, \"Over 40\":0}\n",
    "\n",
    "current_year = 2024\n",
    "\n",
    "# Process each activity\n",
    "for activity in activities_data:\n",
    "    activity_id = activity.get(\"activity_id\")\n",
    "    details = activity.get(\"Activity Details\", {})\n",
    "    rsvpd_list = details.get(\"rsvpd_list\", [])\n",
    "    attended_list = details.get(\"attended_people\", [])\n",
    "    \n",
    "    # Update global counts\n",
    "    total_rsvpd += len(rsvpd_list)\n",
    "    total_attended += len(attended_list)\n",
    "    \n",
    "    # Update people's activities lists\n",
    "    for yid in rsvpd_list:\n",
    "        if yid in people_by_id:\n",
    "            people_by_id[yid][\"activities_rsvpd\"].append(activity_id)\n",
    "    for yid in attended_list:\n",
    "        if yid in people_by_id:\n",
    "            people_by_id[yid][\"activities_attended\"].append(activity_id)\n",
    "    \n",
    "    # Gender and age calculations\n",
    "    for yid in rsvpd_list:\n",
    "        person = people_by_id.get(yid)\n",
    "        if person:\n",
    "            gender = person.get(\"PII\", {}).get(\"gender\", \"Not specified\")\n",
    "            if gender not in gender_count_rsvpd:\n",
    "                gender_count_rsvpd[gender] = 0\n",
    "            gender_count_rsvpd[gender] += 1\n",
    "    \n",
    "    for yid in attended_list:\n",
    "        person = people_by_id.get(yid)\n",
    "        if person:\n",
    "            # Gender count for attended\n",
    "            gender = person.get(\"PII\", {}).get(\"gender\", \"Not specified\")\n",
    "            if gender not in gender_count_attended:\n",
    "                gender_count_attended[gender] = 0\n",
    "            gender_count_attended[gender] += 1\n",
    "            \n",
    "            # Age group for attended\n",
    "            yob = person.get(\"PII\", {}).get(\"year_of_birth\")\n",
    "            if yob:\n",
    "                age = current_year - yob\n",
    "                ag = age_group(age)\n",
    "                age_groups_count_attended[ag] += 1\n",
    "\n",
    "# Determine the major age group of attendees\n",
    "# Find the age group with the highest count\n",
    "major_age_group = max(age_groups_count_attended, key=age_groups_count_attended.get)\n",
    "\n",
    "# Print analysis results\n",
    "print(\"Analysis Results:\")\n",
    "print(f\"Total RSVPd: {total_rsvpd}\")\n",
    "print(f\"Total Attended: {total_attended}\")\n",
    "print(\"Gender breakdown for RSVPd:\", gender_count_rsvpd)\n",
    "print(\"Gender breakdown for Attended:\", gender_count_attended)\n",
    "print(\"Attended Age Groups:\", age_groups_count_attended)\n",
    "print(f\"Major Age Group of Attendees: {major_age_group}\")\n",
    "\n",
    "# Update people.json with the new fields (activities_rsvpd, activities_attended)\n",
    "with open(people_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(people_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Also update people.csv to include these columns\n",
    "people_csv = './data/people.csv'\n",
    "file_exists = os.path.exists(people_csv)\n",
    "if file_exists:\n",
    "    # Load current CSV and rewrite with new columns\n",
    "    # We assume we have all other columns from the previous generation\n",
    "    # We'll need to know all fields. Let's just load one person to guess fields\n",
    "    fieldnames = list(people_data[0].keys())\n",
    "    \n",
    "    # Flatten PII or other nested fields if any? \n",
    "    # If the existing CSV was flattened previously, we may need to re-flatten.\n",
    "    # For simplicity, let's assume CSV was a direct flatten. We'll re-flatten now.\n",
    "    \n",
    "    # We'll create a flatten function for person record similar to before:\n",
    "    def flatten_person(person):\n",
    "        items = {}\n",
    "        def recurse(d, prefix=\"\"):\n",
    "            for k,v in d.items():\n",
    "                new_key = f\"{prefix}_{k}\" if prefix else k\n",
    "                if isinstance(v, dict):\n",
    "                    recurse(v, new_key)\n",
    "                elif isinstance(v, list) and not isinstance(v, str):\n",
    "                    # For activities_rsvpd and activities_attended just join by comma\n",
    "                    if new_key in [\"activities_rsvpd\", \"activities_attended\"]:\n",
    "                        items[new_key] = \", \".join(map(str,v))\n",
    "                    else:\n",
    "                        # For other lists, also join by comma\n",
    "                        items[new_key] = \", \".join(map(str,v))\n",
    "                else:\n",
    "                    items[new_key] = v if v is not None else \"\"\n",
    "        recurse(person)\n",
    "        return items\n",
    "    \n",
    "    # Flatten all people\n",
    "    flattened_people = [flatten_person(p) for p in people_data]\n",
    "    \n",
    "    # Collect fieldnames from flattened data\n",
    "    all_fields = set()\n",
    "    for fp in flattened_people:\n",
    "        all_fields.update(fp.keys())\n",
    "    all_fields = sorted(all_fields)\n",
    "    \n",
    "    # Write updated CSV\n",
    "    with open(people_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=all_fields, quoting=csv.QUOTE_ALL)\n",
    "        writer.writeheader()\n",
    "        for fp in flattened_people:\n",
    "            writer.writerow(fp)\n",
    "    \n",
    "    print(\"people.csv updated with activities_rsvpd and activities_attended columns.\")\n",
    "else:\n",
    "    print(\"people.csv not found, no CSV update performed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-activity analysis saved to ../data/activity_analysis.json\n"
     ]
    }
   ],
   "source": [
    "# Cell: Save Per-Activity Analysis to a JSON File\n",
    "\n",
    "import json\n",
    "\n",
    "current_year = 2024\n",
    "\n",
    "def age_group(age):\n",
    "    if age < 18:\n",
    "        return \"Under 18\"\n",
    "    elif 18 <= age <= 25:\n",
    "        return \"18-25\"\n",
    "    elif 26 <= age <= 40:\n",
    "        return \"26-40\"\n",
    "    else:\n",
    "        return \"Over 40\"\n",
    "\n",
    "activities_filename = '../data/activities_data.json'\n",
    "people_filename = '../data/people.json'\n",
    "analysis_filename = '../data/activity_analysis.json'\n",
    "\n",
    "# Load people data\n",
    "with open(people_filename, 'r', encoding='utf-8') as f:\n",
    "    people_data = json.load(f)\n",
    "\n",
    "# Create a lookup by Youth_ID\n",
    "people_by_id = {p[\"Youth_ID\"]: p for p in people_data if \"Youth_ID\" in p}\n",
    "\n",
    "# Load activities\n",
    "with open(activities_filename, 'r', encoding='utf-8') as f:\n",
    "    activities_data = json.load(f)\n",
    "\n",
    "activity_analysis_data = {}\n",
    "\n",
    "for activity in activities_data:\n",
    "    activity_id = activity.get(\"activity_id\")\n",
    "    details = activity.get(\"Activity Details\", {})\n",
    "    rsvpd_list = details.get(\"rsvpd_list\", [])\n",
    "    attended_list = details.get(\"attended_people\", [])\n",
    "    \n",
    "    # Counts\n",
    "    total_rsvpd = len(rsvpd_list)\n",
    "    total_attended = len(attended_list)\n",
    "    \n",
    "    # Gender breakdown\n",
    "    gender_count_rsvpd = {\"Male\":0, \"Female\":0, \"Not specified\":0}\n",
    "    gender_count_attended = {\"Male\":0, \"Female\":0, \"Not specified\":0}\n",
    "    \n",
    "    # Age groups for attended\n",
    "    age_groups_count_attended = {\"Under 18\":0, \"18-25\":0, \"26-40\":0, \"Over 40\":0}\n",
    "    \n",
    "    for yid in rsvpd_list:\n",
    "        person = people_by_id.get(yid)\n",
    "        if person:\n",
    "            gender = person.get(\"PII\", {}).get(\"gender\", \"Not specified\")\n",
    "            if gender not in gender_count_rsvpd:\n",
    "                gender_count_rsvpd[gender] = 0\n",
    "            gender_count_rsvpd[gender] += 1\n",
    "    \n",
    "    for yid in attended_list:\n",
    "        person = people_by_id.get(yid)\n",
    "        if person:\n",
    "            gender = person.get(\"PII\", {}).get(\"gender\", \"Not specified\")\n",
    "            if gender not in gender_count_attended:\n",
    "                gender_count_attended[gender] = 0\n",
    "            gender_count_attended[gender] += 1\n",
    "            \n",
    "            yob = person.get(\"PII\", {}).get(\"year_of_birth\")\n",
    "            if yob:\n",
    "                age = current_year - yob\n",
    "                ag = age_group(age)\n",
    "                age_groups_count_attended[ag] += 1\n",
    "    \n",
    "    # Determine major age group for this activity\n",
    "    if sum(age_groups_count_attended.values()) > 0:\n",
    "        major_age_group = max(age_groups_count_attended, key=age_groups_count_attended.get)\n",
    "    else:\n",
    "        major_age_group = None\n",
    "    \n",
    "    activity_analysis_data[activity_id] = {\n",
    "        \"activity_name\": details.get(\"activity_name\"),\n",
    "        \"total_rsvpd\": total_rsvpd,\n",
    "        \"total_attended\": total_attended,\n",
    "        \"gender_breakdown_rsvpd\": gender_count_rsvpd,\n",
    "        \"gender_breakdown_attended\": gender_count_attended,\n",
    "        \"age_groups_attended\": age_groups_count_attended,\n",
    "        \"major_age_group_attendees\": major_age_group\n",
    "    }\n",
    "\n",
    "# Save the per-activity analysis\n",
    "with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(activity_analysis_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Per-activity analysis saved to {analysis_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activity Details:\n",
      "ID: ACT-1737152194-RW1Z79\n",
      "Name: Cross-group needs-based archive\n",
      "Type: Networking\n",
      "Description: Assume glass within budget fly set whom discuss safe nor hope.\n",
      "Target Audience: Students\n",
      "Start Date: 2025-02-16T01:16:34.794345\n",
      "End Date: 2025-02-21T01:16:34.794345\n",
      "Location: Virtual (Online)\n",
      "Number of Participants Expected: 168\n",
      "Key Partners/Sponsors: []\n",
      "Activity Goals/Outcomes: Particular including change guess evidence clearly close child if compare.\n",
      "RSVP'd List Count: 9\n",
      "Attended List Count: 1\n",
      "\n",
      "Activity Analysis:\n",
      "Total RSVPd: 9\n",
      "Total Attended: 1\n",
      "Gender breakdown for RSVPd: {'Male': 0, 'Female': 4, 'Not specified': 5}\n",
      "Gender breakdown for Attended: {'Male': 0, 'Female': 1, 'Not specified': 0}\n",
      "Attended Age Groups: {'Under 18': 0, '18-25': 0, '26-40': 1, 'Over 40': 0}\n",
      "Major Age Group of Attendees: 26-40\n"
     ]
    }
   ],
   "source": [
    "# Cell: User Input to Query Activity Details and Analysis\n",
    "\n",
    "import json\n",
    "\n",
    "activities_filename = '../data/activities_data.json'\n",
    "analysis_filename = '../data/activity_analysis.json'\n",
    "\n",
    "# Load activities\n",
    "with open(activities_filename, 'r', encoding='utf-8') as f:\n",
    "    activities_data = json.load(f)\n",
    "\n",
    "# Load activity analysis\n",
    "with open(analysis_filename, 'r', encoding='utf-8') as f:\n",
    "    activity_analysis_data = json.load(f)\n",
    "\n",
    "# User input for activity name\n",
    "search_name = input(\"Enter activity name/title to search: \").strip()\n",
    "\n",
    "# Find activity by name\n",
    "found_activities = [a for a in activities_data if a.get(\"Activity Details\", {}).get(\"activity_name\") == search_name]\n",
    "\n",
    "if not found_activities:\n",
    "    print(\"No activity found with that name.\")\n",
    "else:\n",
    "    # Assuming activity names are unique or taking the first if multiple found\n",
    "    activity = found_activities[0]\n",
    "    activity_id = activity.get(\"activity_id\")\n",
    "    \n",
    "    details = activity.get(\"Activity Details\", {})\n",
    "    analysis = activity_analysis_data.get(activity_id, {})\n",
    "    \n",
    "    print(\"\\nActivity Details:\")\n",
    "    print(f\"ID: {activity_id}\")\n",
    "    print(f\"Name: {details.get('activity_name')}\")\n",
    "    print(f\"Type: {details.get('activity_type')}\")\n",
    "    print(f\"Description: {details.get('description')}\")\n",
    "    print(f\"Target Audience: {details.get('target_audience')}\")\n",
    "    print(f\"Start Date: {details.get('start_date')}\")\n",
    "    print(f\"End Date: {details.get('end_date')}\")\n",
    "    print(f\"Location: {details.get('location')}\")\n",
    "    print(f\"Number of Participants Expected: {details.get('number_of_participants_expected')}\")\n",
    "    print(f\"Key Partners/Sponsors: {details.get('key_partners_sponsors')}\")\n",
    "    print(f\"Activity Goals/Outcomes: {details.get('activity_goals_outcomes')}\")\n",
    "    print(f\"RSVP'd List Count: {len(details.get('rsvpd_list', []))}\")\n",
    "    print(f\"Attended List Count: {len(details.get('attended_people', []))}\")\n",
    "    \n",
    "    # Print analysis results\n",
    "    if analysis:\n",
    "        print(\"\\nActivity Analysis:\")\n",
    "        print(f\"Total RSVPd: {analysis.get('total_rsvpd')}\")\n",
    "        print(f\"Total Attended: {analysis.get('total_attended')}\")\n",
    "        print(\"Gender breakdown for RSVPd:\", analysis.get('gender_breakdown_rsvpd'))\n",
    "        print(\"Gender breakdown for Attended:\", analysis.get('gender_breakdown_attended'))\n",
    "        print(\"Attended Age Groups:\", analysis.get('age_groups_attended'))\n",
    "        print(f\"Major Age Group of Attendees: {analysis.get('major_age_group_attendees')}\")\n",
    "    else:\n",
    "        print(\"\\nNo analysis data found for this activity.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "people-workbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
